name: Daily Supermarket Scraper Run

on:
  push:
    branches:
      - main
  # Descomenta la siguiente sección si deseas ejecutar este workflow en un horario programado
  # schedule:
  #   # Ejecuta todos los días a las 12:00 UTC
  #   - cron: '0 12 * * *'

jobs:
  run-scraper:
    runs-on: ubuntu-latest

    env:
      GCS_PASSWORD: ${{ secrets.GCS_PASSWORD }}
      GCS_USER_ROOT: ${{ secrets.GCS_USER_ROOT }}
      GCS_DATABASE: ${{ secrets.GCS_DATABASE }}
      GCS_HOST: ${{ secrets.GCS_HOST }}
      GCP_CREDENTIALS: ${{ secrets.GCP_CREDENTIALS }} # Asegúrate de haber agregado esto a tus secrets en GitHub
      INSTANCE_CONNECTION_NAME: ${{ secrets.INSTANCE_CONNECTION_NAME }} # Añade esto también a tus secrets

    permissions:
      contents: 'read'
      id-token: 'write'

    steps:
    - uses: actions/checkout@v2
    
    - id: 'auth'
      uses: 'google-github-actions/auth@v2'
      with:
        credentials_json: '${{ secrets.GCP_CREDENTIALS }}'

        
    - name: 'Set up Cloud SDK'
      uses: 'google-github-actions/setup-gcloud@v2'
      with:
        version: '>= 363.0.0'

    - name: 'Use gcloud CLI'
      run: 'gcloud info'

    - name: 'Set up Python'
      uses: actions/setup-python@v2
      with:
        python-version: '3.8'
        
    - name: 'Install dependencies'
      run: |
        python -m pip install --upgrade pip
        pip install -r requirements.txt
        pip install selenium webdriver_manager

    - name: 'Run script'
      run: python main.py --correr-todo
